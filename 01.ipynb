{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"設置隨機種子\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def my_collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    \n",
    "    max_length = max(len(item) for item in data)\n",
    "    \n",
    "    padded_data = [item + [0] * (max_length - len(item)) for item in data]\n",
    "    \n",
    "    padded_data = torch.tensor(padded_data, dtype=torch.float32).unsqueeze(2)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    return padded_data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class USG_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        seed: int = 42,\n",
    "        mode: str = \"train\",\n",
    "        max_len: int = 400,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.seed = seed\n",
    "        self.mode = mode\n",
    "        self.max_len = max_len  # 设定要统一的向量长度\n",
    "        self.samples = [os.path.join(self.root, filename) for filename in os.listdir(self.root)]\n",
    "\n",
    "    def to_tensor(self, x):\n",
    "        return torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    # def pad_or_trim(self, array, target_len):\n",
    "    #     if len(array) < target_len:\n",
    "    #         padded_array = np.pad(array, (0, target_len - len(array)), 'constant')\n",
    "    #     else:\n",
    "    #         padded_array = array[:target_len]\n",
    "    #     return padded_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        with open(path, \"r\") as json_file:\n",
    "            data = json.load(json_file)  \n",
    "            x = data['sequence']\n",
    "            label = data['label']\n",
    "\n",
    "\n",
    "        # x_padded = self.pad_or_trim(x, self.max_len)\n",
    "\n",
    "        # x_tensor = self.to_tensor(x).unsqueeze(0)\n",
    "        # label_tensor = self.to_tensor(label).unsqueeze(0).unsqueeze(1)\n",
    "        \n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        output_size,\n",
    "        forecast_steps,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        dropout=0.5,\n",
    "    ):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.forecast_steps = forecast_steps\n",
    "\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm_encoder = nn.LSTM(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size * forecast_steps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, (hidden, cell) = self.lstm_encoder(x, None)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        out = out.view(-1, self.forecast_steps, self.output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        lr: float,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "    ):\n",
    "        \"\"\"初始化訓練器\"\"\"\n",
    "        self.epochs_run = 0\n",
    "        # 解析 opt 的必要參數\n",
    "        self.lr = lr\n",
    "        self.device = \"cuda:1\"\n",
    "        self.eta_min = 1e-6\n",
    "        self.max_epochs = 100\n",
    "        # self.log_dir = opt.log_dir\n",
    "\n",
    "        self.model = model.to(self.device)  # 模型\n",
    "        self.train_loader = train_loader  # 訓練資料\n",
    "        self.val_loader = val_loader  # 驗證資料\n",
    "        # self.test_loader = test_loader  # 測試資料\n",
    "\n",
    "        # self.criterion = nn.SmoothL1Loss()  # 損失函數\n",
    "        self.criterion = nn.MSELoss()  # 損失函數\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=self.max_epochs, eta_min=self.eta_min, last_epoch=-1\n",
    "        )\n",
    "        # 指標計算器\n",
    "        self.mse_metric = torchmetrics.MeanSquaredError().to(self.device)\n",
    "        self.r2_metric = torchmetrics.R2Score().to(self.device)\n",
    "        self.mae_metric = torchmetrics.MeanAbsoluteError().to(self.device)\n",
    "\n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def log_metrics(self, prefix: str, epoch: int):\n",
    "        self.writer.add_scalar(f\"{prefix}/MSE\", self.mse_metric.compute().item(), epoch)\n",
    "        self.writer.add_scalar(f\"{prefix}/R2\", self.r2_metric.compute().item(), epoch)\n",
    "        self.writer.add_scalar(f\"{prefix}/MAE\", self.mae_metric.compute().item(), epoch)\n",
    "\n",
    "        self.mse_metric.reset()\n",
    "        self.r2_metric.reset()\n",
    "        self.mae_metric.reset()\n",
    "\n",
    "    def train_epoch(self, epoch: int):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        pbar = tqdm(self.train_loader, desc=f\"[{self.device}] Train Epoch {epoch:2d}\")\n",
    "        for src, tgt in pbar:\n",
    "            src, tgt = src.to(self.device), tgt.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(src)\n",
    "            loss = self.criterion(outputs, tgt)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            self.mse_metric(outputs, tgt)\n",
    "            self.mae_metric(outputs, tgt)\n",
    "            self.r2_metric(outputs.view(-1), tgt.view(-1))\n",
    "\n",
    "        self.writer.add_scalar(\"Train/Loss\", total_loss, epoch)\n",
    "        self.writer.add_scalar(\n",
    "            \"Learning Rate\", self.optimizer.param_groups[0][\"lr\"], epoch\n",
    "        )\n",
    "        self.log_metrics(\"Train\", epoch)\n",
    "\n",
    "    def val_epoch(self, epoch: int):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(self.val_loader, desc=f\"[{self.device}] Val Epoch {epoch:2d}\")\n",
    "            for src, tgt in pbar:\n",
    "                src, tgt = src.to(self.device), tgt.to(self.device)\n",
    "                outputs = self.model(src)\n",
    "                loss = self.criterion(outputs, tgt)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                self.mse_metric(outputs, tgt)\n",
    "                self.mae_metric(outputs, tgt)\n",
    "                self.r2_metric(outputs.view(-1), tgt.view(-1))\n",
    "\n",
    "        self.writer.add_scalar(\"Val/Loss\", total_loss, epoch)\n",
    "        self.log_metrics(\"Val\", epoch)\n",
    "\n",
    "    # def test_epoch(self, epoch: int):\n",
    "    #     self.model.eval()\n",
    "    #     total_loss = 0.0\n",
    "    #     with torch.no_grad():\n",
    "    #         pbar = tqdm(self.test_loader, desc=f\"[{self.device}] Test Epoch {epoch:2d}\")\n",
    "    #         for src, tgt in pbar:\n",
    "    #             src, tgt = src.to(self.device), tgt.to(self.device)\n",
    "    #             outputs = self.model(src)\n",
    "    #             loss = self.criterion(outputs, tgt)\n",
    "    #             total_loss += loss.item()\n",
    "\n",
    "    #             self.mse_metric(outputs, tgt)\n",
    "    #             self.mae_metric(outputs, tgt)\n",
    "    #             self.r2_metric(outputs.view(-1), tgt.view(-1))\n",
    "\n",
    "    #     self.writer.add_scalar(\"Test/Loss\", total_loss, epoch)\n",
    "    #     self.log_metrics(\"Test\", epoch)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"主訓練循環\"\"\"\n",
    "        for epoch in range(self.max_epochs):\n",
    "            self.train_epoch(epoch)  # 訓練一個epoch\n",
    "            self.lr_scheduler.step()  # 更新學習率調整器\n",
    "            self.val_epoch(epoch)\n",
    "            # self.test_epoch(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 429, 1])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "batch = next(data_iter)\n",
    "inputs, labels = batch\n",
    "print(inputs.shape)  # 应该是 (batch_size, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[cuda:1] Train Epoch  0: 100%|██████████| 6371/6371 [02:49<00:00, 37.64it/s]\n",
      "[cuda:1] Val Epoch  0: 100%|██████████| 3162/3162 [00:36<00:00, 86.02it/s]\n",
      "[cuda:1] Train Epoch  1: 100%|██████████| 6371/6371 [02:50<00:00, 37.44it/s]\n",
      "[cuda:1] Val Epoch  1: 100%|██████████| 3162/3162 [00:36<00:00, 85.71it/s]\n",
      "[cuda:1] Train Epoch  2: 100%|██████████| 6371/6371 [02:50<00:00, 37.39it/s]\n",
      "[cuda:1] Val Epoch  2: 100%|██████████| 3162/3162 [00:36<00:00, 85.76it/s]\n",
      "[cuda:1] Train Epoch  3: 100%|██████████| 6371/6371 [02:50<00:00, 37.33it/s]\n",
      "[cuda:1] Val Epoch  3: 100%|██████████| 3162/3162 [00:36<00:00, 85.81it/s]\n",
      "[cuda:1] Train Epoch  4: 100%|██████████| 6371/6371 [02:50<00:00, 37.42it/s]\n",
      "[cuda:1] Val Epoch  4: 100%|██████████| 3162/3162 [00:37<00:00, 85.10it/s]\n",
      "[cuda:1] Train Epoch  5: 100%|██████████| 6371/6371 [02:50<00:00, 37.37it/s]\n",
      "[cuda:1] Val Epoch  5: 100%|██████████| 3162/3162 [00:37<00:00, 85.28it/s]\n",
      "[cuda:1] Train Epoch  6: 100%|██████████| 6371/6371 [02:50<00:00, 37.35it/s]\n",
      "[cuda:1] Val Epoch  6: 100%|██████████| 3162/3162 [00:36<00:00, 85.66it/s]\n",
      "[cuda:1] Train Epoch  7: 100%|██████████| 6371/6371 [02:50<00:00, 37.41it/s]\n",
      "[cuda:1] Val Epoch  7: 100%|██████████| 3162/3162 [00:37<00:00, 85.37it/s]\n",
      "[cuda:1] Train Epoch  8: 100%|██████████| 6371/6371 [02:51<00:00, 37.14it/s]\n",
      "[cuda:1] Val Epoch  8: 100%|██████████| 3162/3162 [00:36<00:00, 85.48it/s]\n",
      "[cuda:1] Train Epoch  9: 100%|██████████| 6371/6371 [02:51<00:00, 37.17it/s]\n",
      "[cuda:1] Val Epoch  9: 100%|██████████| 3162/3162 [00:37<00:00, 85.01it/s]\n",
      "[cuda:1] Train Epoch 10: 100%|██████████| 6371/6371 [02:51<00:00, 37.18it/s]\n",
      "[cuda:1] Val Epoch 10: 100%|██████████| 3162/3162 [00:37<00:00, 85.26it/s]\n",
      "[cuda:1] Train Epoch 11: 100%|██████████| 6371/6371 [02:51<00:00, 37.17it/s]\n",
      "[cuda:1] Val Epoch 11: 100%|██████████| 3162/3162 [00:37<00:00, 85.42it/s]\n",
      "[cuda:1] Train Epoch 12: 100%|██████████| 6371/6371 [02:51<00:00, 37.19it/s]\n",
      "[cuda:1] Val Epoch 12: 100%|██████████| 3162/3162 [00:37<00:00, 85.23it/s]\n",
      "[cuda:1] Train Epoch 13: 100%|██████████| 6371/6371 [02:51<00:00, 37.17it/s]\n",
      "[cuda:1] Val Epoch 13: 100%|██████████| 3162/3162 [00:36<00:00, 85.53it/s]\n",
      "[cuda:1] Train Epoch 14: 100%|██████████| 6371/6371 [02:51<00:00, 37.20it/s]\n",
      "[cuda:1] Val Epoch 14: 100%|██████████| 3162/3162 [00:37<00:00, 85.23it/s]\n",
      "[cuda:1] Train Epoch 15: 100%|██████████| 6371/6371 [02:51<00:00, 37.18it/s]\n",
      "[cuda:1] Val Epoch 15: 100%|██████████| 3162/3162 [00:37<00:00, 84.70it/s]\n",
      "[cuda:1] Train Epoch 16: 100%|██████████| 6371/6371 [02:51<00:00, 37.10it/s]\n",
      "[cuda:1] Val Epoch 16: 100%|██████████| 3162/3162 [00:36<00:00, 85.59it/s]\n",
      "[cuda:1] Train Epoch 17: 100%|██████████| 6371/6371 [02:51<00:00, 37.13it/s]\n",
      "[cuda:1] Val Epoch 17: 100%|██████████| 3162/3162 [00:36<00:00, 85.52it/s]\n",
      "[cuda:1] Train Epoch 18: 100%|██████████| 6371/6371 [02:51<00:00, 37.16it/s]\n",
      "[cuda:1] Val Epoch 18: 100%|██████████| 3162/3162 [00:37<00:00, 84.93it/s]\n",
      "[cuda:1] Train Epoch 19: 100%|██████████| 6371/6371 [02:51<00:00, 37.07it/s]\n",
      "[cuda:1] Val Epoch 19: 100%|██████████| 3162/3162 [00:37<00:00, 85.24it/s]\n",
      "[cuda:1] Train Epoch 20: 100%|██████████| 6371/6371 [02:51<00:00, 37.13it/s]\n",
      "[cuda:1] Val Epoch 20: 100%|██████████| 3162/3162 [00:37<00:00, 85.14it/s]\n",
      "[cuda:1] Train Epoch 21: 100%|██████████| 6371/6371 [02:51<00:00, 37.21it/s]\n",
      "[cuda:1] Val Epoch 21: 100%|██████████| 3162/3162 [00:37<00:00, 85.38it/s]\n",
      "[cuda:1] Train Epoch 22: 100%|██████████| 6371/6371 [02:51<00:00, 37.13it/s]\n",
      "[cuda:1] Val Epoch 22: 100%|██████████| 3162/3162 [00:37<00:00, 85.36it/s]\n",
      "[cuda:1] Train Epoch 23: 100%|██████████| 6371/6371 [02:51<00:00, 37.18it/s]\n",
      "[cuda:1] Val Epoch 23: 100%|██████████| 3162/3162 [00:37<00:00, 85.18it/s]\n",
      "[cuda:1] Train Epoch 24: 100%|██████████| 6371/6371 [02:51<00:00, 37.23it/s]\n",
      "[cuda:1] Val Epoch 24: 100%|██████████| 3162/3162 [00:37<00:00, 85.27it/s]\n",
      "[cuda:1] Train Epoch 25: 100%|██████████| 6371/6371 [02:51<00:00, 37.16it/s]\n",
      "[cuda:1] Val Epoch 25: 100%|██████████| 3162/3162 [00:37<00:00, 85.08it/s]\n",
      "[cuda:1] Train Epoch 26: 100%|██████████| 6371/6371 [02:51<00:00, 37.11it/s]\n",
      "[cuda:1] Val Epoch 26: 100%|██████████| 3162/3162 [00:37<00:00, 84.63it/s]\n",
      "[cuda:1] Train Epoch 27: 100%|██████████| 6371/6371 [02:51<00:00, 37.14it/s]\n",
      "[cuda:1] Val Epoch 27: 100%|██████████| 3162/3162 [00:37<00:00, 85.17it/s]\n",
      "[cuda:1] Train Epoch 28: 100%|██████████| 6371/6371 [02:51<00:00, 37.16it/s]\n",
      "[cuda:1] Val Epoch 28: 100%|██████████| 3162/3162 [00:37<00:00, 85.27it/s]\n",
      "[cuda:1] Train Epoch 29: 100%|██████████| 6371/6371 [02:51<00:00, 37.11it/s]\n",
      "[cuda:1] Val Epoch 29: 100%|██████████| 3162/3162 [00:37<00:00, 85.38it/s]\n",
      "[cuda:1] Train Epoch 30: 100%|██████████| 6371/6371 [02:51<00:00, 37.10it/s]\n",
      "[cuda:1] Val Epoch 30: 100%|██████████| 3162/3162 [00:37<00:00, 84.64it/s]\n",
      "[cuda:1] Train Epoch 31: 100%|██████████| 6371/6371 [02:51<00:00, 37.16it/s]\n",
      "[cuda:1] Val Epoch 31: 100%|██████████| 3162/3162 [00:37<00:00, 84.79it/s]\n",
      "[cuda:1] Train Epoch 32: 100%|██████████| 6371/6371 [02:51<00:00, 37.16it/s]\n",
      "[cuda:1] Val Epoch 32: 100%|██████████| 3162/3162 [00:37<00:00, 84.97it/s]\n",
      "[cuda:1] Train Epoch 33: 100%|██████████| 6371/6371 [02:51<00:00, 37.18it/s]\n",
      "[cuda:1] Val Epoch 33: 100%|██████████| 3162/3162 [00:37<00:00, 85.09it/s]\n",
      "[cuda:1] Train Epoch 34: 100%|██████████| 6371/6371 [02:51<00:00, 37.09it/s]\n",
      "[cuda:1] Val Epoch 34: 100%|██████████| 3162/3162 [00:37<00:00, 85.02it/s]\n",
      "[cuda:1] Train Epoch 35: 100%|██████████| 6371/6371 [02:51<00:00, 37.12it/s]\n",
      "[cuda:1] Val Epoch 35: 100%|██████████| 3162/3162 [00:37<00:00, 84.58it/s]\n",
      "[cuda:1] Train Epoch 36: 100%|██████████| 6371/6371 [02:51<00:00, 37.18it/s]\n",
      "[cuda:1] Val Epoch 36: 100%|██████████| 3162/3162 [00:37<00:00, 85.22it/s]\n",
      "[cuda:1] Train Epoch 37: 100%|██████████| 6371/6371 [02:51<00:00, 37.11it/s]\n",
      "[cuda:1] Val Epoch 37: 100%|██████████| 3162/3162 [00:37<00:00, 85.35it/s]\n",
      "[cuda:1] Train Epoch 38: 100%|██████████| 6371/6371 [02:51<00:00, 37.11it/s]\n",
      "[cuda:1] Val Epoch 38: 100%|██████████| 3162/3162 [00:37<00:00, 85.26it/s]\n",
      "[cuda:1] Train Epoch 39: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 39: 100%|██████████| 3162/3162 [00:37<00:00, 84.75it/s]\n",
      "[cuda:1] Train Epoch 40: 100%|██████████| 6371/6371 [02:51<00:00, 37.12it/s]\n",
      "[cuda:1] Val Epoch 40: 100%|██████████| 3162/3162 [00:37<00:00, 85.14it/s]\n",
      "[cuda:1] Train Epoch 41: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 41: 100%|██████████| 3162/3162 [00:37<00:00, 84.89it/s]\n",
      "[cuda:1] Train Epoch 42: 100%|██████████| 6371/6371 [02:52<00:00, 37.00it/s]\n",
      "[cuda:1] Val Epoch 42: 100%|██████████| 3162/3162 [00:37<00:00, 84.76it/s]\n",
      "[cuda:1] Train Epoch 43: 100%|██████████| 6371/6371 [02:51<00:00, 37.09it/s]\n",
      "[cuda:1] Val Epoch 43: 100%|██████████| 3162/3162 [00:37<00:00, 84.90it/s]\n",
      "[cuda:1] Train Epoch 44: 100%|██████████| 6371/6371 [02:51<00:00, 37.06it/s]\n",
      "[cuda:1] Val Epoch 44: 100%|██████████| 3162/3162 [00:37<00:00, 85.24it/s]\n",
      "[cuda:1] Train Epoch 45: 100%|██████████| 6371/6371 [02:51<00:00, 37.07it/s]\n",
      "[cuda:1] Val Epoch 45: 100%|██████████| 3162/3162 [00:37<00:00, 84.97it/s]\n",
      "[cuda:1] Train Epoch 46: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 46: 100%|██████████| 3162/3162 [00:37<00:00, 85.30it/s]\n",
      "[cuda:1] Train Epoch 47: 100%|██████████| 6371/6371 [02:52<00:00, 37.03it/s]\n",
      "[cuda:1] Val Epoch 47: 100%|██████████| 3162/3162 [00:37<00:00, 84.91it/s]\n",
      "[cuda:1] Train Epoch 48: 100%|██████████| 6371/6371 [02:52<00:00, 37.01it/s]\n",
      "[cuda:1] Val Epoch 48: 100%|██████████| 3162/3162 [00:37<00:00, 85.05it/s]\n",
      "[cuda:1] Train Epoch 49: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 49: 100%|██████████| 3162/3162 [00:37<00:00, 84.59it/s]\n",
      "[cuda:1] Train Epoch 50: 100%|██████████| 6371/6371 [02:51<00:00, 37.09it/s]\n",
      "[cuda:1] Val Epoch 50: 100%|██████████| 3162/3162 [00:37<00:00, 84.93it/s]\n",
      "[cuda:1] Train Epoch 51: 100%|██████████| 6371/6371 [02:51<00:00, 37.08it/s]\n",
      "[cuda:1] Val Epoch 51: 100%|██████████| 3162/3162 [00:37<00:00, 84.96it/s]\n",
      "[cuda:1] Train Epoch 52: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 52: 100%|██████████| 3162/3162 [00:37<00:00, 84.74it/s]\n",
      "[cuda:1] Train Epoch 53: 100%|██████████| 6371/6371 [02:52<00:00, 36.98it/s]\n",
      "[cuda:1] Val Epoch 53: 100%|██████████| 3162/3162 [00:37<00:00, 84.71it/s]\n",
      "[cuda:1] Train Epoch 54: 100%|██████████| 6371/6371 [02:52<00:00, 37.03it/s]\n",
      "[cuda:1] Val Epoch 54: 100%|██████████| 3162/3162 [00:37<00:00, 84.77it/s]\n",
      "[cuda:1] Train Epoch 55: 100%|██████████| 6371/6371 [02:52<00:00, 37.04it/s]\n",
      "[cuda:1] Val Epoch 55: 100%|██████████| 3162/3162 [00:37<00:00, 84.76it/s]\n",
      "[cuda:1] Train Epoch 56: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 56: 100%|██████████| 3162/3162 [00:37<00:00, 84.74it/s]\n",
      "[cuda:1] Train Epoch 57: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 57: 100%|██████████| 3162/3162 [00:37<00:00, 84.84it/s]\n",
      "[cuda:1] Train Epoch 58: 100%|██████████| 6371/6371 [02:52<00:00, 37.01it/s]\n",
      "[cuda:1] Val Epoch 58: 100%|██████████| 3162/3162 [00:37<00:00, 84.71it/s]\n",
      "[cuda:1] Train Epoch 59: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 59: 100%|██████████| 3162/3162 [00:37<00:00, 84.62it/s]\n",
      "[cuda:1] Train Epoch 60: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 60: 100%|██████████| 3162/3162 [00:37<00:00, 84.78it/s]\n",
      "[cuda:1] Train Epoch 61: 100%|██████████| 6371/6371 [02:51<00:00, 37.07it/s]\n",
      "[cuda:1] Val Epoch 61: 100%|██████████| 3162/3162 [00:37<00:00, 85.08it/s]\n",
      "[cuda:1] Train Epoch 62: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 62: 100%|██████████| 3162/3162 [00:37<00:00, 84.65it/s]\n",
      "[cuda:1] Train Epoch 63: 100%|██████████| 6371/6371 [02:51<00:00, 37.10it/s]\n",
      "[cuda:1] Val Epoch 63: 100%|██████████| 3162/3162 [00:37<00:00, 85.19it/s]\n",
      "[cuda:1] Train Epoch 64: 100%|██████████| 6371/6371 [02:51<00:00, 37.04it/s]\n",
      "[cuda:1] Val Epoch 64: 100%|██████████| 3162/3162 [00:37<00:00, 85.01it/s]\n",
      "[cuda:1] Train Epoch 65: 100%|██████████| 6371/6371 [02:52<00:00, 37.04it/s]\n",
      "[cuda:1] Val Epoch 65: 100%|██████████| 3162/3162 [00:37<00:00, 84.55it/s]\n",
      "[cuda:1] Train Epoch 66: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 66: 100%|██████████| 3162/3162 [00:37<00:00, 85.20it/s]\n",
      "[cuda:1] Train Epoch 67: 100%|██████████| 6371/6371 [02:51<00:00, 37.06it/s]\n",
      "[cuda:1] Val Epoch 67: 100%|██████████| 3162/3162 [00:37<00:00, 84.96it/s]\n",
      "[cuda:1] Train Epoch 68: 100%|██████████| 6371/6371 [02:52<00:00, 36.97it/s]\n",
      "[cuda:1] Val Epoch 68: 100%|██████████| 3162/3162 [00:37<00:00, 84.70it/s]\n",
      "[cuda:1] Train Epoch 69: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 69: 100%|██████████| 3162/3162 [00:37<00:00, 84.87it/s]\n",
      "[cuda:1] Train Epoch 70: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 70: 100%|██████████| 3162/3162 [00:37<00:00, 85.12it/s]\n",
      "[cuda:1] Train Epoch 71: 100%|██████████| 6371/6371 [02:52<00:00, 36.98it/s]\n",
      "[cuda:1] Val Epoch 71: 100%|██████████| 3162/3162 [00:37<00:00, 84.62it/s]\n",
      "[cuda:1] Train Epoch 72: 100%|██████████| 6371/6371 [02:52<00:00, 37.01it/s]\n",
      "[cuda:1] Val Epoch 72: 100%|██████████| 3162/3162 [00:37<00:00, 84.97it/s]\n",
      "[cuda:1] Train Epoch 73: 100%|██████████| 6371/6371 [02:52<00:00, 36.94it/s]\n",
      "[cuda:1] Val Epoch 73: 100%|██████████| 3162/3162 [00:37<00:00, 85.03it/s]\n",
      "[cuda:1] Train Epoch 74: 100%|██████████| 6371/6371 [02:52<00:00, 37.01it/s]\n",
      "[cuda:1] Val Epoch 74: 100%|██████████| 3162/3162 [00:37<00:00, 85.22it/s]\n",
      "[cuda:1] Train Epoch 75: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 75: 100%|██████████| 3162/3162 [00:37<00:00, 84.98it/s]\n",
      "[cuda:1] Train Epoch 76: 100%|██████████| 6371/6371 [02:51<00:00, 37.05it/s]\n",
      "[cuda:1] Val Epoch 76: 100%|██████████| 3162/3162 [00:37<00:00, 85.07it/s]\n",
      "[cuda:1] Train Epoch 77: 100%|██████████| 6371/6371 [02:52<00:00, 36.97it/s]\n",
      "[cuda:1] Val Epoch 77: 100%|██████████| 3162/3162 [00:37<00:00, 84.78it/s]\n",
      "[cuda:1] Train Epoch 78: 100%|██████████| 6371/6371 [02:52<00:00, 37.03it/s]\n",
      "[cuda:1] Val Epoch 78: 100%|██████████| 3162/3162 [00:37<00:00, 84.92it/s]\n",
      "[cuda:1] Train Epoch 79: 100%|██████████| 6371/6371 [02:51<00:00, 37.06it/s]\n",
      "[cuda:1] Val Epoch 79: 100%|██████████| 3162/3162 [00:37<00:00, 84.70it/s]\n",
      "[cuda:1] Train Epoch 80: 100%|██████████| 6371/6371 [02:52<00:00, 36.91it/s]\n",
      "[cuda:1] Val Epoch 80: 100%|██████████| 3162/3162 [00:37<00:00, 84.50it/s]\n",
      "[cuda:1] Train Epoch 81: 100%|██████████| 6371/6371 [02:52<00:00, 36.98it/s]\n",
      "[cuda:1] Val Epoch 81: 100%|██████████| 3162/3162 [00:37<00:00, 84.94it/s]\n",
      "[cuda:1] Train Epoch 82: 100%|██████████| 6371/6371 [02:52<00:00, 36.99it/s]\n",
      "[cuda:1] Val Epoch 82: 100%|██████████| 3162/3162 [00:37<00:00, 84.96it/s]\n",
      "[cuda:1] Train Epoch 83: 100%|██████████| 6371/6371 [02:52<00:00, 36.98it/s]\n",
      "[cuda:1] Val Epoch 83: 100%|██████████| 3162/3162 [00:37<00:00, 85.11it/s]\n",
      "[cuda:1] Train Epoch 84: 100%|██████████| 6371/6371 [02:52<00:00, 37.00it/s]\n",
      "[cuda:1] Val Epoch 84: 100%|██████████| 3162/3162 [00:37<00:00, 84.81it/s]\n",
      "[cuda:1] Train Epoch 85: 100%|██████████| 6371/6371 [02:52<00:00, 37.04it/s]\n",
      "[cuda:1] Val Epoch 85: 100%|██████████| 3162/3162 [00:37<00:00, 85.07it/s]\n",
      "[cuda:1] Train Epoch 86: 100%|██████████| 6371/6371 [02:52<00:00, 36.98it/s]\n",
      "[cuda:1] Val Epoch 86: 100%|██████████| 3162/3162 [00:37<00:00, 84.89it/s]\n",
      "[cuda:1] Train Epoch 87: 100%|██████████| 6371/6371 [02:52<00:00, 37.01it/s]\n",
      "[cuda:1] Val Epoch 87: 100%|██████████| 3162/3162 [00:37<00:00, 84.67it/s]\n",
      "[cuda:1] Train Epoch 88: 100%|██████████| 6371/6371 [02:52<00:00, 36.98it/s]\n",
      "[cuda:1] Val Epoch 88: 100%|██████████| 3162/3162 [00:37<00:00, 84.89it/s]\n",
      "[cuda:1] Train Epoch 89: 100%|██████████| 6371/6371 [02:52<00:00, 36.97it/s]\n",
      "[cuda:1] Val Epoch 89: 100%|██████████| 3162/3162 [00:37<00:00, 84.74it/s]\n",
      "[cuda:1] Train Epoch 90: 100%|██████████| 6371/6371 [02:52<00:00, 36.96it/s]\n",
      "[cuda:1] Val Epoch 90: 100%|██████████| 3162/3162 [00:37<00:00, 84.52it/s]\n",
      "[cuda:1] Train Epoch 91: 100%|██████████| 6371/6371 [02:52<00:00, 36.96it/s]\n",
      "[cuda:1] Val Epoch 91: 100%|██████████| 3162/3162 [00:37<00:00, 84.57it/s]\n",
      "[cuda:1] Train Epoch 92: 100%|██████████| 6371/6371 [02:52<00:00, 37.01it/s]\n",
      "[cuda:1] Val Epoch 92: 100%|██████████| 3162/3162 [00:37<00:00, 85.11it/s]\n",
      "[cuda:1] Train Epoch 93: 100%|██████████| 6371/6371 [02:52<00:00, 37.03it/s]\n",
      "[cuda:1] Val Epoch 93: 100%|██████████| 3162/3162 [00:37<00:00, 84.63it/s]\n",
      "[cuda:1] Train Epoch 94: 100%|██████████| 6371/6371 [02:52<00:00, 37.03it/s]\n",
      "[cuda:1] Val Epoch 94: 100%|██████████| 3162/3162 [00:37<00:00, 84.68it/s]\n",
      "[cuda:1] Train Epoch 95: 100%|██████████| 6371/6371 [02:52<00:00, 37.02it/s]\n",
      "[cuda:1] Val Epoch 95: 100%|██████████| 3162/3162 [00:37<00:00, 84.74it/s]\n",
      "[cuda:1] Train Epoch 96: 100%|██████████| 6371/6371 [02:52<00:00, 36.96it/s]\n",
      "[cuda:1] Val Epoch 96: 100%|██████████| 3162/3162 [00:37<00:00, 84.41it/s]\n",
      "[cuda:1] Train Epoch 97: 100%|██████████| 6371/6371 [02:52<00:00, 36.97it/s]\n",
      "[cuda:1] Val Epoch 97: 100%|██████████| 3162/3162 [00:37<00:00, 84.62it/s]\n",
      "[cuda:1] Train Epoch 98: 100%|██████████| 6371/6371 [02:51<00:00, 37.06it/s]\n",
      "[cuda:1] Val Epoch 98: 100%|██████████| 3162/3162 [00:37<00:00, 84.94it/s]\n",
      "[cuda:1] Train Epoch 99: 100%|██████████| 6371/6371 [02:52<00:00, 37.04it/s]\n",
      "[cuda:1] Val Epoch 99: 100%|██████████| 3162/3162 [00:37<00:00, 84.99it/s]\n"
     ]
    }
   ],
   "source": [
    "seed = 87\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "forecast_steps = 1\n",
    "\n",
    "seed_everything(seed)\n",
    "train_dataset = USG_Dataset(\n",
    "    \"./data/training\",\n",
    "    seed=seed,\n",
    "    mode='train'\n",
    ")\n",
    "val_dataset = USG_Dataset(\n",
    "    \"./data/validation\",\n",
    "    seed=seed,\n",
    "    mode='val'\n",
    ")\n",
    "# test_dataset = USG_Dataset(\n",
    "#     \"./data/raw_data.csv\",\n",
    "#     seed=seed,\n",
    "#     mode='test'\n",
    "# )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=my_collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=my_collate_fn\n",
    ")\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "# )\n",
    "model = LSTMModel(\n",
    "    input_size=1,\n",
    "    output_size=1,\n",
    "    forecast_steps=forecast_steps,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model, lr, train_loader, val_loader)#, test_loader)\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "as_pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
